---
title: "Final Project"
author: "Maureen Muthengi"
date: "2024-07-06"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

Instacart Market Basket Analysis

Which products will an Instacart consumer purchase again?

The Instacart Market Basket Analysis is a project that aims to predict which products a consumer is likely to purchase again during their next order. By analyzing historical purchase data from millions of orders, the goal is to uncover patterns and insights about consumer behavior. This analysis helps in understanding customer preferences, improving product recommendations, and optimizing inventory management. Key aspects include examining product reorder rates, identifying frequent product combinations, and leveraging machine learning models to make accurate predictions about future purchases.

For this analysis, I will use a logistic regression model to predict the likelihood of a product being reordered. Logistic regression is suitable for this task as it can handle binary outcomes (reordered or not reordered) and provides probabilities that help in making informed predictions. By predicting which products an Instacart consumer will purchase again, businesses can tailor marketing strategies, enhance customer satisfaction, and drive sales growth through personalized shopping experiences.

## Load the necessary Packages
```{r}

library(tidyverse)
library(caret)
library(ROCR)
library(dplyr)
library(tidymodels)
library(openintro)
library(ggplot2)
library(broom)
```

## Load the Data

For this project we will Load the customer dataset and perform an initial exploration to understand its structure and contents. This step involves reading the CSV file and inspecting the first few rows to get a sense of the data.

```{r, echo=FALSE}
customer_data <- read.csv("~/Documents/Summer 2024/R_Activities_Summer 2024/Assignment/Website (Portfolio)/instacart-market-basket-analysis/order_products__prior.csv")
head(customer_data)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

```{r}
glimpse(customer_data)
```


## Data Preprocessing
Clean the data by handling missing values and encoding categorical variables. In this case, we may not need extensive preprocessing since the dataset is already structured:

```{r}
# Check the structure of the data
str(customer_data)
```

Checking for missing values
```{r}
# Check for missing values
colSums(is.na(customer_data))
```

## Step-by-Step Logistic Regression:
1. Understanding Logistic Regression:
Logistic regression is used when the dependent variable (or outcome) is categorical. It predicts the probability of occurrence of an event by fitting data to a logistic curve.

2. Data Preparation:

Dependent Variable (Response): reordered (binary categorical: 0 or 1).
Independent Variables (Predictors): Typically numeric or categorical predictors like order_id, product_id, add_to_cart_order.

3. Data Exploration:
Explore your data to understand distributions, relationships, and any initial insights.

4. Model Building:
Formulate the Model: Specify the logistic regression model equation:

logit(𝑝) =𝛽0+𝛽1𝑥1+𝛽2𝑥2+⋯+𝛽𝑛𝑥𝑛
 
where 
𝑝p is the probability of the dependent variable, and 𝛽0,𝛽1,…,𝛽𝑛β 0 are coefficients.


## Computing Probabilities
Compute the probabilities of reordered being 1 using the logistic regression model.

```{r}
# Fit logistic regression model
model <- glm(reordered ~ ., data = customer_data, family = "binomial")
```

```{r}
# Predict probabilities
probabilities <- predict(model, type = "response")
```

```{r}
# Append probabilities to the customer_data for reference
customer_data$predicted_probability <- probabilities

```

```{r}
# View the probabilities
head(customer_data[, c("reordered", "predicted_probability")])
```
## Calculating Conditional Odds
Calculating the conditional odds of products being reordered based on the logistic regression model can provide valuable insights into how each product contributes to the likelihood of being reordered. 

After fitting the logistic regression model, you can use the model coefficients to calculate the conditional odds for each product. Conditional odds represent the change in odds of an event (in this case, product being reordered) associated with a one-unit change in the predictor variable (product_id).

Step-by-Step Calculation:
Extract Coefficients from the Model:
First, extract the coefficients (beta) from the logistic regression model.

```{r}
# fitted logistic regression model
coefficients <- coef(model)
coefficients
```


write the regression model equation here


Calculate Odds Ratios (Conditional Odds):
Use the coefficients to calculate the odds ratios, which represent the conditional odds for each product (product_id).

Here exp(coefficients[-1]) calculates the exponential of each coefficient (excluding the intercept) to obtain the odds ratios.
```{r}
# Calculate odds ratios (conditional odds)
odds_ratios <- exp(coefficients[-1])
odds_ratios
```


```{r}
# Create a dataframe to store product_id and corresponding odds ratios
product_odds <- data.frame(product_id = names(odds_ratios), odds_ratio = odds_ratios)
product_odds
```

## Interpretation

Based on the above results:

order_id and product_id: These variables have odds ratios close to 1 (1.0000000 and 1.0000007 respectively). An odds ratio of 1 suggests that there is no change in the odds of reordered for a one-unit increase in these variables. This could imply that these variables may not significantly influence the odds of reordered based on the current model.

add_to_cart_order: This variable has an odds ratio of approximately 0.9625898. An odds ratio less than 1 suggests that for every one-unit increase in add_to_cart_order, the odds of reordered decrease by approximately 3.74% ((1−0.9625898)×100)

order_id and product_id do not show a significant impact on the odds of reordered based on the current model.
add_to_cart_order has a slight negative impact, implying that products added later to the cart might be slightly less likely to be reordered.

## Refining the Model

Due to the insignificant results we need to optimize its predictive power and interpretability by identifying and addressing issues such as irrelevant variables or potential interactions.

1. Variable Selection:
Identify Variables with Minimal Impact:
Coefficient Significance: Review the coefficients and their significance levels (p-values). Variables with high p-values (typically > 0.05) may indicate they are not statistically significant and can potentially be removed.
Now considering the relevance of each variable to the outcome (reordered). Variables like order_id and product_id might not directly influence reorder likelihood and could be candidates for removal.
```{r}
# Checking significance of coefficients
summary(model)
```
based on these results, the significant Variables are product_id and add_to_cart_order as they appear to be statistically significant predictors of reordered.

Explore Interactions between Variables:
2. Interaction Terms: predictors (product_id and add_to_cart_order) are significant based on their coefficients and p-values.
Create interaction terms to capture potential combined effects of these predictors on reordered.
Interaction Effects: Investigate if the effect of one predictor variable on the outcome varies depending on the value of another predictor. 
```{r}
# Adding interaction term between product_id and add_to_cart_order
model_interaction <- glm(reordered ~ product_id * add_to_cart_order, data = customer_data, family = "binomial")
model_interaction
```

Interpretation of Interaction Terms:
Coefficient Interpretation: Examine the coefficients of the interaction terms. A significant interaction indicates that the effect of one predictor on the outcome depends on the level of the other predictor.
Significance Testing: Check the p-values associated with the interaction terms to determine if they are statistically significant.

Plotting Interactions:
Visualize interactions using plots to understand how the relationship between predictors and reordered changes across different levels of the interacting variables.

```{r}
#Plotting interactions (if significant)
plot(customer_data$product_id, customer_data$add_to_cart_order, col = customer_data$reordered)

```


Conclusion
Exploring interactions between significant predictors (product_id and add_to_cart_order) allows you to capture nuanced relationships that may improve your logistic regression model's ability to predict reordered. It’s essential to interpret the results carefully and validate the model enhancements to ensure robustness and generalizability.

## Fitting the Model
Using the `{tidymodel}` method for fitting model.

To fit a logistic regression model using the {tidymodels} framework in R, we can follow a structured approach that integrates data preprocessing, model fitting, and evaluation. Here’s how you can proceed step-by-step:

Step-by-Step Approach
1. Data Preprocessing
Ensure your data is prepared, including handling missing values and encoding categorical variables if necessary. Here’s a brief recap on preprocessing:


Converting the variable to a factor
Factor Variable: Logistic regression models in R require the outcome variable (reordered) to be a factor with appropriate levels (0 and 1) for binary classification.
```{r}
# Convert reordered to a factor in the training data
customer_data$reordered <- factor(customer_data$reordered, levels = c(0, 1))

```


2. Model Specification and Fitting


Fit the Model Using {tidymodels}:

Now, fit the logistic regression model using the {tidymodels} framework:

```{r}
# Taking a smaller sample of customer_data
set.seed(123)  # For reproducibility
sample_size <- 10000  # this can be adjusted as needed

customer_data_sample <- customer_data %>%
  sample_n(sample_size)

# Checking the dimensions of the sampled data
dim(customer_data_sample)

# Fitting the logistic regression model on the sampled data
set.seed(123)
train_control <- trainControl(method = "cv", number = 10)
cv_model <- train(
  reordered ~ order_id + product_id + add_to_cart_order,
  data = customer_data_sample,
  method = "glm",
  trControl = train_control,
  family = "binomial"
)

# Printing the cross-validation results
cv_model
```
```{r}
# The {tidymodels} method for logistic regression requires that the response be a factor variable
# convert 'reordered' to a factor variable
customer_data <- customer_data %>%
  mutate(reordered = as.factor(reordered))

# Define logistic regression specification
logistic_spec <- logistic_reg() %>%
  set_engine("glm", family = "binomial")

# Fit the logistic regression model
model_fit <- logistic_spec %>%
  fit(reordered ~ product_id + add_to_cart_order, data = customer_data)

# View coefficients and summary
summary(model_fit) %>%
  tidy() %>%
  knitr::kable(digits = 3)
```


3. Model Evaluation
Evaluate the model's performance using metrics such as ROC curve and AUC:

```{r}
# Check if test_data exists
exists("test_data")
```
 


```{r}
# Split data into training and testing sets
set.seed(123)  # for reproducibility
sample_size <- 10000  # this can be adjusted as needed
index <- createDataPartition(customer_data$reordered, p = 0.8, list = FALSE)
train_data <- customer_data[index, ]
test_data <- customer_data[-index, ]
```

```{r}
# Confirm dimensions of the datasets
dim(train_data)
dim(test_data)
```

## Train the Logistic Regression Model

```{r}
library(tidymodels)

sample_size <- 10000  # Adjust sample size as needed

# Split data into training and testing sets
set.seed(123)  # for reproducibility
index <- createDataPartition(customer_data$reordered, p = 0.8, list = FALSE)
train_data <- customer_data[index, ]
test_data <- customer_data[-index, ]

# Subsample if needed
train_data <- sample_n(train_data, sample_size)

# Define the logistic regression model
logistic_model <- 
  logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

# Define the recipe (data preprocessing steps)
data_recipe <- 
  recipe(reordered ~ ., data = train_data) %>%
  step_scale(all_predictors()) %>%
  step_center(all_predictors())

# Combine model and recipe into a workflow
workflow <- 
  workflow() %>%
  add_recipe(data_recipe) %>%
  add_model(logistic_model)

# Train the model
model_fit <- fit(workflow, data = train_data)


```


```{r}
# Install and load ROCR package
install.packages("ROCR")
library(ROCR)

# Compute ROC curve
pred <- prediction(predictions$`1`, test_data$reordered)
perf <- performance(pred, "tpr", "fpr")

# Plot ROC curve
plot(perf, main = "ROC Curve", col = "blue")
```



4. Model Interpretation
Interpret the coefficients and significance of predictors

```{r}
# Extract coefficients and their significance
tidy(model_fit)
```
Make predictions
```{r}
# Make predictions on the test data
# Make predictions on the test data
predictions <- predict(model_fit, test_data, type = "prob") %>%
  bind_cols(test_data)
predictions
```



```{r}
# Convert reordered to a factor for yardstick functions
test_data$reordered <- as.factor(test_data$reordered)
```

Fit the model

```{r}
library(tidymodels)
library(caret)

# Sample size
sample_size <- 10000  # Adjust this as needed

# Split data into training and testing sets
set.seed(123)  # for reproducibility
index <- createDataPartition(customer_data$reordered, p = 0.8, list = FALSE)
train_data <- customer_data[index, ]
test_data <- customer_data[-index, ]

# Subsample the training data
train_data <- sample_n(train_data, sample_size)

# Define the logistic regression model
logistic_model <- 
  logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

# Define the recipe (data preprocessing steps)
data_recipe <- 
  recipe(reordered ~ ., data = train_data) %>%
  step_scale(all_predictors()) %>%
  step_center(all_predictors())

# Combine model and recipe into a workflow
workflow <- 
  workflow() %>%
  add_recipe(data_recipe) %>%
  add_model(logistic_model)

# Train the model
model_fit <- fit(workflow, data = train_data)

# Make predictions on the test data
predictions <- predict(model_fit, test_data, type = "prob") %>%
  bind_cols(test_data)

# Convert 'reordered' to factor in test data
test_data$reordered <- as.factor(test_data$reordered)

# Evaluate the model
roc_auc_value <- roc_auc(predictions, truth = reordered, .pred_1)
roc_curve_data <- roc_curve(predictions, truth = reordered, .pred_1)

# Print the ROC AUC
print(roc_auc_value)

# Plot the ROC curve
autoplot(roc_curve_data)
```

Evaluate the model
```{r}
library(tidymodels)
library(caret)

# Sample size
sample_size <- 10000  # Adjust this as needed

# Split data into training and testing sets
set.seed(123)  # for reproducibility
index <- createDataPartition(customer_data$reordered, p = 0.8, list = FALSE)
train_data <- customer_data[index, ]
test_data <- customer_data[-index, ]

# Subsample the training data
train_data <- sample_n(train_data, sample_size)

# Define the logistic regression model
logistic_model <- 
  logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

# Define the recipe (data preprocessing steps)
data_recipe <- 
  recipe(reordered ~ ., data = train_data) %>%
  step_scale(all_predictors()) %>%
  step_center(all_predictors())

# Combine model and recipe into a workflow
workflow <- 
  workflow() %>%
  add_recipe(data_recipe) %>%
  add_model(logistic_model)

# Train the model
model_fit <- fit(workflow, data = train_data)

# Make predictions on the test data
predictions <- predict(model_fit, test_data, type = "prob") %>%
  bind_cols(predict(model_fit, test_data, type = "class") %>%
              rename(predicted_class = .pred_class)) %>%
  bind_cols(test_data)

# Convert 'reordered' to factor in test data
test_data$reordered <- as.factor(test_data$reordered)

# Evaluate the model
roc_auc_value <- roc_auc(predictions, truth = reordered, .pred_1)
roc_curve_data <- roc_curve(predictions, truth = reordered, .pred_1)

# Print the ROC AUC
print(roc_auc_value)

# Plot the ROC curve
autoplot(roc_curve_data)

# Create the confusion matrix
conf_matrix <- conf_mat(predictions, truth = reordered, estimate = predicted_class)
print(conf_matrix)

```
## Deviance Residuals

the deviance residuals.

  
```{r}
# To store residuals and create row number variable
new_model <- augment(new_model, type.predict = "response", 
                      type.residuals = "deviance") %>% 
                      mutate(id = row_number())

# Plot residuals vs fitted values
ggplot(data = mult_log_aug, aes(x = .fitted, y = .resid)) + 
geom_point() + 
geom_hline(yintercept = 0, color = "red") + 
labs(x = "Fitted values", 
     y = "Deviance residuals", 
     title = "Deviance residuals vs. fitted")
     
# Plot residuals vs row number
ggplot(data = mult_log_aug, aes(x = id, y = .resid)) + 
geom_point() + 
geom_hline(yintercept = 0, color = "red") + 
labs(x = "id", 
     y = "Deviance residuals", 
     title = "Deviance residuals vs. id")
```
```{r}

```
